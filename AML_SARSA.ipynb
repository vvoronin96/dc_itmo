{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\victor\\anaconda3\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\users\\victor\\anaconda3\\lib\\site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\victor\\anaconda3\\lib\\site-packages (from gym) (1.5.2)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in c:\\users\\victor\\anaconda3\\lib\\site-packages (from gym) (7.2.0)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\victor\\anaconda3\\lib\\site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\victor\\anaconda3\\lib\\site-packages (from gym) (1.19.2)\n",
      "Requirement already satisfied: future in c:\\users\\victor\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the libraries, create our own 6x6 environment. S denotes the starting point. F - ice is safe (frozen), H - hole, G - goal. The parameter is_slippery = False is responsible for slipping. That is, if the agent chose the action to go right, then it will move to the corresponding state. In the general case, due to the “slipping”, one may find itself in a different state. We also copied from the GYM library and slightly modified the function generate_random_map, in order to generate arbitrary maps based on random_seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9 # Discount coefficient gamma\n",
    "random_seed = 5 #Random seed\n",
    "epsilon = 0.1\n",
    "time_delay = 1 # Time delay when rendering the game process after training (seconds)\n",
    "lr_rate = 0.9 #Learning rate alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your map\n",
      "\n",
      "\u001b[41mS\u001b[0mHFHFF\n",
      "FFFFFF\n",
      "FFHFFF\n",
      "FFFFFF\n",
      "FFFHHF\n",
      "FFFFFG\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def generate_random_map(size, p, sd):\n",
    "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
    "    :param size: size of each side of the grid\n",
    "    :param p: probability that a tile is frozen\n",
    "    \"\"\"\n",
    "    valid = False\n",
    "    np.random.seed(sd)\n",
    "\n",
    "    # DFS to check that it's a valid path.\n",
    "    def is_valid(res):\n",
    "        frontier, discovered = [], set()\n",
    "        frontier.append((0,0))\n",
    "        while frontier:\n",
    "            r, c = frontier.pop()\n",
    "            if not (r,c) in discovered:\n",
    "                discovered.add((r,c))\n",
    "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "                for x, y in directions:\n",
    "                    r_new = r + x\n",
    "                    c_new = c + y\n",
    "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
    "                        continue\n",
    "                    if res[r_new][c_new] == 'G':\n",
    "                        return True\n",
    "                    if (res[r_new][c_new] not in '#H'):\n",
    "                        frontier.append((r_new, c_new))\n",
    "        return False\n",
    "\n",
    "    while not valid:\n",
    "        p = min(1, p)\n",
    "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
    "        res[0][0] = 'S'\n",
    "        res[-1][-1] = 'G'\n",
    "        valid = is_valid(res)\n",
    "    return [\"\".join(x) for x in res]\n",
    "\n",
    "# Map generation\n",
    "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Create our map\n",
    "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Initialize environment\n",
    "print(\"Your map\")\n",
    "env.render() #Render the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q.shape\n",
    "epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm #progress bar\n",
    "def choose_action(state):\n",
    "    action=0\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "        action = np.random.randint(0,env.action_space.n) #***\n",
    "    else:\n",
    "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "def learn(state, state2, reward, action, action2, done):\n",
    "    if done:\n",
    "          Q[state, action] = Q[state, action] + lr_rate * (reward - Q[state, action])\n",
    "    else:\n",
    "          Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * Q[state2, action2] - Q[state, action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 40000/40000 [01:46<00:00, 374.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первые 5 побед\t 757\n",
      "Всего побед\t 30615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inititalization\n",
    "np.random.seed(random_seed)\n",
    "total_games = 40000\n",
    "max_steps = 100\n",
    "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
    "wins_arr = []\n",
    "min_game = 0\n",
    "\n",
    "for game in tqdm(range(total_games)):\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    action = choose_action(state) #Choice of action at the very beginning of each game\n",
    "    while t < max_steps:\n",
    "        if np.sum(wins_arr[-5:]) == 5 and min_game == 0:\n",
    "            min_game = game\n",
    "        t += 1\n",
    "        state2, reward, done, info = env.step(action)\n",
    "        action2 = choose_action(state2) #choice of action for the next step of the game, as well as for updating the value of the current action\n",
    "        if t == max_steps:\n",
    "            done = True  \n",
    "        learn(state, state2, reward, action, action2, done) # action2 is also passed to the training function\n",
    "        state = state2\n",
    "        action = action2\n",
    "\n",
    "        if done and reward == 1:\n",
    "            wins_arr.append(1)\n",
    "            break\n",
    "        if done:\n",
    "            wins_arr.append(0)\n",
    "            break\n",
    "\n",
    "\"\"\"#Main cycle\n",
    "for game in tqdm(range(total_games)):\n",
    "    state = env.reset()\n",
    "    t = 0\n",
    "    while t < max_steps:\n",
    "        if np.sum(wins_arr[-5:]) == 5 and min_game == 0:\n",
    "            min_game = game\n",
    "        t += 1\n",
    "        action = choose_action(state)\n",
    "        state2, reward, done, info = env.step(action)\n",
    "        if t == max_steps:\n",
    "              done = True  \n",
    "        learn(state, state2, reward, action, done)\n",
    "        state = state2\n",
    "        \n",
    "        if done and reward == 1:\n",
    "            wins_arr.append(1)\n",
    "            break\n",
    "        if done:\n",
    "            wins_arr.append(0)\n",
    "            break\"\"\"\n",
    "print(\"Первые 5 побед\\t\", min_game)\n",
    "print(\"Всего побед\\t\", np.sum(wins_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SHFHFF\n",
      "FFFFFF\n",
      "FFHFFF\n",
      "FFFFFF\n",
      "FFFHHF\n",
      "FFFF\u001b[41mF\u001b[0mG\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#Greedy action selection\n",
    "def choose_action_one_game(state):\n",
    "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
    "    return action\n",
    "\n",
    "states=[]#Array to save agent states during the game\n",
    "t = 0\n",
    "state = env.reset()\n",
    "wn = 0\n",
    "while(t<100):\n",
    "    env.render()\n",
    "    time.sleep(time_delay)\n",
    "    clear_output(wait=True)\n",
    "    action = choose_action_one_game(state)  \n",
    "    state2, reward, done, info = env.step(action)  \n",
    "    states.append(state)\n",
    "    state = state2\n",
    "    t += 1\n",
    "    if done and reward == 1:\n",
    "        wn=1\n",
    "    if done:\n",
    "        break\n",
    "    if wn == 1:\n",
    "      print(\"!!!WIN!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1cd5f593550>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_maze_pic(maze):\n",
    "    maze_pic=[]\n",
    "    for i in range(len(maze)):\n",
    "        row = []\n",
    "        for j in range(len(maze[i])):\n",
    "            if maze[i][j] == 'S':\n",
    "                row.append(0)\n",
    "            if maze[i][j] == 'F':\n",
    "                row.append(0)\n",
    "            if maze[i][j] == 'H':\n",
    "                row.append(1)\n",
    "            if maze[i][j] == 'G':\n",
    "                row.append(0)\n",
    "        maze_pic.append(row)\n",
    "    maze_pic = np.array(maze_pic)\n",
    "    return maze_pic\n",
    "  \n",
    "\n",
    "#Make maze fit to plot\n",
    "maze_pic = make_maze_pic(random_map)\n",
    "nrows, ncols = maze_pic.shape\n",
    "\n",
    "#Arrays of picture elements\n",
    "rw = np.remainder(states,nrows)\n",
    "cl = np.floor_divide(states,nrows)\n",
    "if wn == 1:\n",
    "    rw = np.append(rw, [nrows-1])\n",
    "    cl = np.append(cl,[ncols-1])\n",
    "\n",
    "#Picture plotting\n",
    "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
    "ax1.clear()\n",
    "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
    "ax1.set_yticklabels([])\n",
    "ax1.grid(True)\n",
    "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
    "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
    "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
    "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
    "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
    "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
    "ax1.imshow(maze_pic, cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
